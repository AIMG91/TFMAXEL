{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db78b3f8",
   "metadata": {},
   "source": [
    "# 01 — SARIMAX con exógenas (por Store)\n",
    "\n",
    "**Objetivo:** forecasting de `Weekly_Sales` semanal por `Store` usando SARIMAX con variables exógenas.\n",
    "\n",
    "## Supuesto experimental (oracle exog)\n",
    "Se asume disponibilidad de todas las covariables exógenas durante el horizonte de predicción (escenario oracle).\n",
    "\n",
    "## Outputs estándar\n",
    "- `outputs/predictions/sarimax_exog_predictions.csv` con: `Store, Date, y_true, y_pred, model`\n",
    "- `outputs/metrics/sarimax_exog_metrics_global.csv`\n",
    "- `outputs/metrics/sarimax_exog_metrics_by_store.csv`\n",
    "- `outputs/figures/sarimax_exog_plot_*.png`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "658b7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Imports y configuración\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.common import (\n",
    "    SplitConfig,\n",
    "    TEST_WEEKS,\n",
    "    compute_metrics,\n",
    "    load_data,\n",
    "    make_features,\n",
    "    save_outputs,\n",
    "    temporal_split,\n",
    " )\n",
    "\n",
    "MODEL_NAME = 'sarimax_exog'\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'Walmart_Sales.csv'\n",
    "METADATA_PATH = PROJECT_ROOT / 'outputs' / 'metadata.json'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'outputs'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4fcee13",
   "metadata": {},
   "source": [
    "## 1) Cargar metadata (split + features)\n",
    "Esto garantiza consistencia entre modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f951a790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: {'train_start': '2010-02-05', 'train_end': '2012-07-06', 'val_start': '2012-07-13', 'val_end': '2012-08-31', 'test_start': '2012-09-07', 'test_end': '2012-10-26'}\n",
      "N features: 16\n"
     ]
    }
   ],
   "source": [
    "if METADATA_PATH.exists():\n",
    "    metadata = json.loads(METADATA_PATH.read_text(encoding='utf-8'))\n",
    "    split = metadata['split']\n",
    "    feature_cols = metadata['features']\n",
    "    split_cfg = SplitConfig(\n",
    "        train_start=pd.Timestamp(split['train_start']),\n",
    "        train_end=pd.Timestamp(split['train_end']),\n",
    "        val_start=pd.Timestamp(split['val_start']),\n",
    "        val_end=pd.Timestamp(split['val_end']),\n",
    "        test_start=pd.Timestamp(split['test_start']),\n",
    "        test_end=pd.Timestamp(split['test_end']),\n",
    "    )\n",
    "    print('Split (metadata):', split)\n",
    "    print('N features:', len(feature_cols))\n",
    "else:\n",
    "    metadata = None\n",
    "    split = None\n",
    "    feature_cols = None\n",
    "    split_cfg = None\n",
    "    print('metadata.json not found; will compute split with TEST_WEEKS=', TEST_WEEKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9be695a",
   "metadata": {},
   "source": [
    "## 2) Carga de datos + features\n",
    "- Parseo/orden\n",
    "- Construcción de lags/rolling (sin leakage)\n",
    "- Exógenas alineadas por fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96292d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4095, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(DATA_PATH)\n",
    "df_feat, feature_cols_auto = make_features(df, add_calendar=True)\n",
    "if feature_cols is None:\n",
    "    feature_cols = feature_cols_auto\n",
    "\n",
    "# Importante: para entrenar, debes decidir cómo tratar NaNs creados por lags/rolling\n",
    "# Opción típica: descartar filas con NaNs en features (por store al inicio)\n",
    "model_df = df_feat.dropna(subset=feature_cols + ['Weekly_Sales']).copy()\n",
    "model_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617f238d",
   "metadata": {},
   "source": [
    "## 3) Split temporal\n",
    "Reutiliza exactamente el split definido en el notebook 00."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147dc146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3375 360 360\n"
     ]
    }
   ],
   "source": [
    "if split_cfg is None:\n",
    "    train_df, val_df, test_df, split_cfg = temporal_split(df, test_weeks=TEST_WEEKS)\n",
    "else:\n",
    "    train_df = df[df['Date'].between(split_cfg.train_start, split_cfg.train_end)].copy()\n",
    "    val_df = df[df['Date'].between(split_cfg.val_start, split_cfg.val_end)].copy()\n",
    "    test_df = df[df['Date'].between(split_cfg.test_start, split_cfg.test_end)].copy()\n",
    "\n",
    "# Aplicar el split sobre model_df (ya sin NaNs por lags)\n",
    "train = model_df[model_df['Date'].between(split_cfg.train_start, split_cfg.train_end)].copy()\n",
    "val = model_df[model_df['Date'].between(split_cfg.val_start, split_cfg.val_end)].copy()\n",
    "test = model_df[model_df['Date'].between(split_cfg.test_start, split_cfg.test_end)].copy()\n",
    "\n",
    "print(len(train), len(val), len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8552729a",
   "metadata": {},
   "source": [
    "## 4) Entrenamiento del modelo\n",
    "Implementación SARIMAX por tienda con exógenas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40bba37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed stores: 0\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from warnings import filterwarnings\n",
    "\n",
    "filterwarnings(\"ignore\")\n",
    "\n",
    "# SARIMAX ya modela dependencias temporales; usamos exógenas + calendario (sin lags/rolling)\n",
    "sarimax_exog_cols = [c for c in feature_cols if not c.startswith(\"lag_\") and not c.startswith(\"roll_\")]\n",
    "\n",
    "preds = pd.Series(index=test.index, dtype=float)\n",
    "failed_stores = []\n",
    "\n",
    "for store, g_train in train.groupby(\"Store\"):\n",
    "    g_test = test[test[\"Store\"] == store]\n",
    "    if g_test.empty or g_train.empty:\n",
    "        continue\n",
    "\n",
    "    y_train = g_train[\"Weekly_Sales\"].astype(float)\n",
    "    X_train = g_train[sarimax_exog_cols].astype(float)\n",
    "    X_test = g_test[sarimax_exog_cols].astype(float)\n",
    "\n",
    "    try:\n",
    "        model = SARIMAX(\n",
    "            y_train,\n",
    "            exog=X_train,\n",
    "            order=(1, 1, 1),\n",
    "            seasonal_order=(0, 0, 0, 0),\n",
    "            enforce_stationarity=False,\n",
    "            enforce_invertibility=False,\n",
    "        )\n",
    "        res = model.fit(disp=False)\n",
    "        forecast = res.get_forecast(steps=len(g_test), exog=X_test)\n",
    "        y_pred_store = forecast.predicted_mean\n",
    "        preds.loc[g_test.index] = y_pred_store.values\n",
    "    except Exception:\n",
    "        failed_stores.append(int(store))\n",
    "        preds.loc[g_test.index] = y_train.mean()\n",
    "\n",
    "# Relleno de seguridad si alguna predicción quedó NaN\n",
    "if preds.isna().any():\n",
    "    preds = preds.fillna(train[\"Weekly_Sales\"].mean())\n",
    "\n",
    "y_pred_test = preds.values\n",
    "print(\"Failed stores:\", len(failed_stores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b084bc65",
   "metadata": {},
   "source": [
    "## 5) Métricas (MAE, RMSE, sMAPE)\n",
    "Se reporta:\n",
    "- Global\n",
    "- Por store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "292f86d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(          model            MAE           RMSE      sMAPE\n",
       " 0  sarimax_exog  124157.680285  169022.469951  10.889343,\n",
       "           model  Store            MAE           RMSE     sMAPE\n",
       " 0  sarimax_exog      1  122537.806903  130906.969556  7.594821\n",
       " 1  sarimax_exog      2  145186.688393  153599.094294  7.509888\n",
       " 2  sarimax_exog      3   30852.759826   33342.089262  7.611823\n",
       " 3  sarimax_exog      4  143754.257288  154725.388471  6.557401\n",
       " 4  sarimax_exog      5   10757.029110   13023.135273  3.271099)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame({\n",
    "    'Store': test['Store'].astype(int).values,\n",
    "    'Date': test['Date'].values,\n",
    "    'y_true': test['Weekly_Sales'].values,\n",
    "    'y_pred': np.asarray(y_pred_test, dtype=float),\n",
    "    'model': MODEL_NAME,\n",
    "})\n",
    "\n",
    "global_metrics = compute_metrics(pred_df['y_true'].values, pred_df['y_pred'].values)\n",
    "metrics_global_df = pd.DataFrame([{'model': MODEL_NAME, **global_metrics}])\n",
    "\n",
    "by_store = []\n",
    "for store, g in pred_df.groupby('Store'):\n",
    "    m = compute_metrics(g['y_true'].values, g['y_pred'].values)\n",
    "    by_store.append({'model': MODEL_NAME, 'Store': int(store), **m})\n",
    "metrics_by_store_df = pd.DataFrame(by_store).sort_values('Store')\n",
    "\n",
    "metrics_global_df, metrics_by_store_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8835062d",
   "metadata": {},
   "source": [
    "## 6) Guardado de outputs estándar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5df579fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'predictions': 'c:\\\\Users\\\\usuario\\\\Documents\\\\Master AI\\\\TFM\\\\MEMORIA 2.0\\\\outputs\\\\predictions\\\\sarimax_exog_predictions.csv',\n",
       " 'metrics_global': 'c:\\\\Users\\\\usuario\\\\Documents\\\\Master AI\\\\TFM\\\\MEMORIA 2.0\\\\outputs\\\\metrics\\\\sarimax_exog_metrics_global.csv',\n",
       " 'metrics_by_store': 'c:\\\\Users\\\\usuario\\\\Documents\\\\Master AI\\\\TFM\\\\MEMORIA 2.0\\\\outputs\\\\metrics\\\\sarimax_exog_metrics_by_store.csv'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths = save_outputs(\n",
    "    model_name=MODEL_NAME,\n",
    "    predictions=pred_df,\n",
    "    metrics_global=metrics_global_df,\n",
    "    metrics_by_store=metrics_by_store_df,\n",
    "    output_dir=OUTPUTS_DIR,\n",
    ")\n",
    "paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74769251",
   "metadata": {},
   "source": [
    "## 7) Figuras\n",
    "- 3 tiendas: real vs predicción en test\n",
    "- Distribución del error (`y_true - y_pred`)\n",
    "\n",
    "Guardar PNGs en `outputs/figures/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21ec0b82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "FIG_DIR = OUTPUTS_DIR / \"figures\"\n",
    "FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Selección de 3 tiendas (mayor media de ventas en test)\n",
    "top_stores = (\n",
    "    pred_df.groupby(\"Store\")[\"y_true\"]\n",
    "    .mean()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(3)\n",
    "    .index\n",
    "    .tolist()\n",
    ")\n",
    "\n",
    "for store in top_stores:\n",
    "    g = pred_df[pred_df[\"Store\"] == store].sort_values(\"Date\")\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(g[\"Date\"], g[\"y_true\"], label=\"y_true\")\n",
    "    plt.plot(g[\"Date\"], g[\"y_pred\"], label=\"y_pred\")\n",
    "    plt.title(f\"Store {store} — SARIMAX\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Weekly_Sales\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG_DIR / f\"{MODEL_NAME}_plot_store_{store}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Distribución de error\n",
    "errors = pred_df[\"y_true\"] - pred_df[\"y_pred\"]\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.histplot(errors, bins=30, kde=True)\n",
    "plt.title(\"Error distribution (y_true - y_pred)\")\n",
    "plt.xlabel(\"Error\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(FIG_DIR / f\"{MODEL_NAME}_plot_error_dist.png\", dpi=150)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
