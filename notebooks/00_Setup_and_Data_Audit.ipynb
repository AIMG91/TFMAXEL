{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "123a6714",
   "metadata": {},
   "source": [
    "# 00 — Setup & Data Audit (Walmart Sales)\n",
    "\n",
    "**Objetivo:** validar el dataset local, realizar una EDA mínima, confirmar frecuencia semanal, definir un split temporal fijo (train/val/test) y generar `outputs/metadata.json`.\n",
    "\n",
    "## Supuesto experimental (oracle exog)\n",
    "Durante el horizonte de predicción se asume disponibilidad de **todas las variables exógenas** (`Holiday_Flag`, `Temperature`, `Fuel_Price`, `CPI`, `Unemployment`).\n",
    "Este supuesto se mantiene **para todos los modelos** y debe declararse también en la memoria.\n",
    "\n",
    "## Norma de oro (consistencia)\n",
    "- Mismo split temporal y mismas métricas para todos los modelos\n",
    "- Features de target (lags/rolling) construidas usando **solo pasado** (sin leakage)\n",
    "- Normalización/estandarización (si aplica en un modelo): fit SOLO en train; aplicar a val/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17c73c22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: c:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\n",
      "Data path: c:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\data\\Walmart_Sales.csv\n",
      "Python: 3.13.1 | Platform: Windows-11-10.0.26100-SP0\n"
     ]
    }
   ],
   "source": [
    "# Imports y configuración base\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import os\n",
    "import platform\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Asegura imports desde src/\n",
    "PROJECT_ROOT = Path.cwd().parent\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "import importlib\n",
    "import src.common as common\n",
    "importlib.reload(common)\n",
    "\n",
    "from src.common import (\n",
    "    EXOG_COLUMNS,\n",
    "    REQUIRED_COLUMNS,\n",
    "    DEFAULT_LAGS,\n",
    "    compute_metrics,\n",
    "    load_data,\n",
    "    make_features,\n",
    "    temporal_split,\n",
    "    write_metadata,\n",
    "  )\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "\n",
    "DATA_PATH = PROJECT_ROOT / 'data' / 'Walmart_Sales.csv'\n",
    "OUTPUTS_DIR = PROJECT_ROOT / 'outputs'\n",
    "OUTPUTS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "print('Data path:', DATA_PATH)\n",
    "print('Python:', sys.version.split()[0], '| Platform:', platform.platform())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "317db947",
   "metadata": {},
   "source": [
    "## 1) Carga y validación del dataset\n",
    "Validaciones mínimas:\n",
    "- Columnas esperadas\n",
    "- Tipos básicos\n",
    "- Fechas parseables\n",
    "- Orden temporal por Store-Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "166c02e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-05</td>\n",
       "      <td>1643690.90</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-12</td>\n",
       "      <td>1641957.44</td>\n",
       "      <td>1</td>\n",
       "      <td>38.51</td>\n",
       "      <td>2.548</td>\n",
       "      <td>211.242170</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-19</td>\n",
       "      <td>1611968.17</td>\n",
       "      <td>0</td>\n",
       "      <td>39.93</td>\n",
       "      <td>2.514</td>\n",
       "      <td>211.289143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>1409727.59</td>\n",
       "      <td>0</td>\n",
       "      <td>46.63</td>\n",
       "      <td>2.561</td>\n",
       "      <td>211.319643</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2010-03-05</td>\n",
       "      <td>1554806.68</td>\n",
       "      <td>0</td>\n",
       "      <td>46.50</td>\n",
       "      <td>2.625</td>\n",
       "      <td>211.350143</td>\n",
       "      <td>8.106</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store       Date  Weekly_Sales  Holiday_Flag  Temperature  Fuel_Price  \\\n",
       "0      1 2010-02-05    1643690.90             0        42.31       2.572   \n",
       "1      1 2010-02-12    1641957.44             1        38.51       2.548   \n",
       "2      1 2010-02-19    1611968.17             0        39.93       2.514   \n",
       "3      1 2010-02-26    1409727.59             0        46.63       2.561   \n",
       "4      1 2010-03-05    1554806.68             0        46.50       2.625   \n",
       "\n",
       "          CPI  Unemployment  \n",
       "0  211.096358         8.106  \n",
       "1  211.242170         8.106  \n",
       "2  211.289143         8.106  \n",
       "3  211.319643         8.106  \n",
       "4  211.350143         8.106  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(DATA_PATH)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bd1eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (6435, 8)\n",
      "Columns: ['Store', 'Date', 'Weekly_Sales', 'Holiday_Flag', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
      "Date range: 2010-02-05 -> 2012-10-26\n",
      "Stores: 45\n",
      "Duplicated (Store, Date): 0\n"
     ]
    }
   ],
   "source": [
    "print('Shape:', df.shape)\n",
    "print('Columns:', list(df.columns))\n",
    "print('Date range:', df['Date'].min().date(), '->', df['Date'].max().date())\n",
    "print('Stores:', df['Store'].nunique())\n",
    "\n",
    "# Chequeos rápidos\n",
    "assert set(REQUIRED_COLUMNS).issubset(df.columns)\n",
    "assert df[['Store','Date']].isna().sum().sum() == 0\n",
    "\n",
    "# Duplicados Store-Date (debería ser 0 en una serie semanal limpia)\n",
    "dup = df.duplicated(['Store','Date']).sum()\n",
    "print('Duplicated (Store, Date):', int(dup))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdcb4683",
   "metadata": {},
   "source": [
    "## 2) EDA mínima\n",
    "Incluye:\n",
    "- Missing values\n",
    "- Semanas por store\n",
    "- Estadísticos básicos de `Weekly_Sales`\n",
    "- Señales simples de outliers (percentiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff9ce744",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store           0\n",
       "Date            0\n",
       "Weekly_Sales    0\n",
       "Holiday_Flag    0\n",
       "Temperature     0\n",
       "Fuel_Price      0\n",
       "CPI             0\n",
       "Unemployment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Missing values por columna\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45418645",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     45.0\n",
       "mean     143.0\n",
       "std        0.0\n",
       "min      143.0\n",
       "25%      143.0\n",
       "50%      143.0\n",
       "75%      143.0\n",
       "max      143.0\n",
       "Name: Date, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weeks_per_store = df.groupby('Store')['Date'].nunique().sort_values()\n",
    "weeks_per_store.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce8ca8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6.435000e+03\n",
       "mean     1.046965e+06\n",
       "std      5.643666e+05\n",
       "min      2.099862e+05\n",
       "1%       2.531031e+05\n",
       "5%       3.084267e+05\n",
       "50%      9.607460e+05\n",
       "95%      2.049179e+06\n",
       "99%      2.404035e+06\n",
       "max      3.818686e+06\n",
       "Name: Weekly_Sales, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sales_desc = df['Weekly_Sales'].describe(percentiles=[0.01,0.05,0.5,0.95,0.99])\n",
    "sales_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce41163",
   "metadata": {},
   "source": [
    "## 3) Confirmación de frecuencia semanal\n",
    "Chequeo: diferencia entre fechas consecutivas por tienda. En un dataset semanal, lo más común es 7 días."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95512ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "delta_days\n",
       "7.0    6390\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sorted = df.sort_values(['Store','Date']).copy()\n",
    "df_sorted['delta_days'] = df_sorted.groupby('Store')['Date'].diff().dt.days\n",
    "delta_counts = df_sorted['delta_days'].value_counts(dropna=True).sort_index()\n",
    "delta_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7dbd40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Share of 7-day deltas: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de saltos semanales (7 días)\n",
    "total_deltas = df_sorted['delta_days'].notna().sum()\n",
    "weekly_deltas = (df_sorted['delta_days'] == 7).sum()\n",
    "print('Share of 7-day deltas:', weekly_deltas / total_deltas if total_deltas else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad1988",
   "metadata": {},
   "source": [
    "## 4) Definición del split temporal (fijo)\n",
    "Se define un split temporal global por fechas (mismos cortes para todas las tiendas):\n",
    "- Train: desde la primera fecha hasta antes de Validation\n",
    "- Validation: últimas `val_weeks` semanas antes de Test\n",
    "- Test: últimas `test_weeks` semanas\n",
    "\n",
    "Este split se reutiliza idéntico en todos los notebooks de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "764ded2d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "iLocation based boolean indexing on an integer type is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m VAL_WEEKS = \u001b[32m8\u001b[39m\n\u001b[32m      2\u001b[39m TEST_WEEKS = \u001b[32m8\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m train_df, val_df, test_df, split_cfg = \u001b[43mtemporal_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_weeks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVAL_WEEKS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_weeks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTEST_WEEKS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m split_cfg\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\src\\common.py:120\u001b[39m, in \u001b[36mtemporal_split\u001b[39m\u001b[34m(df, val_weeks, test_weeks)\u001b[39m\n\u001b[32m    117\u001b[39m val_start = unique_dates.iloc[-(test_weeks + val_weeks)]\n\u001b[32m    118\u001b[39m train_start = unique_dates.iloc[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m train_end = \u001b[43munique_dates\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43munique_dates\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_start\u001b[49m\u001b[43m]\u001b[49m.iloc[-\u001b[32m1\u001b[39m]\n\u001b[32m    121\u001b[39m val_end = unique_dates.iloc[unique_dates < test_start].iloc[-\u001b[32m1\u001b[39m]\n\u001b[32m    122\u001b[39m test_end = unique_dates.iloc[-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1191\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1189\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1190\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1191\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1738\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1735\u001b[39m     key = np.asarray(key)\n\u001b[32m   1737\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m com.is_bool_indexer(key):\n\u001b[32m-> \u001b[39m\u001b[32m1738\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getbool_axis(key, axis=axis)\n\u001b[32m   1741\u001b[39m \u001b[38;5;66;03m# a list of integers\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\usuario\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\indexing.py:1578\u001b[39m, in \u001b[36m_iLocIndexer._validate_key\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1576\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(key, \u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key.index, Index):\n\u001b[32m   1577\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key.index.inferred_type == \u001b[33m\"\u001b[39m\u001b[33minteger\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1578\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[32m   1579\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33miLocation based boolean \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1580\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mindexing on an integer type \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1581\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mis not available\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1582\u001b[39m         )\n\u001b[32m   1583\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1584\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33miLocation based boolean indexing cannot use \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1585\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33man indexable as a mask\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1586\u001b[39m     )\n\u001b[32m   1587\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: iLocation based boolean indexing on an integer type is not available"
     ]
    }
   ],
   "source": [
    "VAL_WEEKS = 8\n",
    "TEST_WEEKS = 8\n",
    "\n",
    "train_df, val_df, test_df, split_cfg = temporal_split(df, val_weeks=VAL_WEEKS, test_weeks=TEST_WEEKS)\n",
    "split_cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbd2e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train:', train_df['Date'].min().date(), '->', train_df['Date'].max().date(), 'rows', len(train_df))\n",
    "print('Val  :', val_df['Date'].min().date(), '->', val_df['Date'].max().date(), 'rows', len(val_df))\n",
    "print('Test :', test_df['Date'].min().date(), '->', test_df['Date'].max().date(), 'rows', len(test_df))\n",
    "\n",
    "# Sanity: no overlap\n",
    "assert train_df['Date'].max() < val_df['Date'].min()\n",
    "assert val_df['Date'].max() < test_df['Date'].min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f4a7aab",
   "metadata": {},
   "source": [
    "## 5) Features comunes (para todos los modelos)\n",
    "Se definen features comunes centralizadas:\n",
    "- Lags del target: `lag_1, lag_2, lag_4, lag_8, lag_52`\n",
    "- Rolling stats del target (solo pasado): `roll_mean_4, roll_mean_8, roll_std_8`\n",
    "- Exógenas: `Holiday_Flag, Temperature, Fuel_Price, CPI, Unemployment`\n",
    "- (Opcional) calendario: `weekofyear, month, year`\n",
    "\n",
    "Nota: estas features se calculan en el dataframe completo pero usando únicamente información pasada (shift), por lo que **no usan el target futuro**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e388ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feat, feature_cols = make_features(df, lags=DEFAULT_LAGS, add_calendar=True)\n",
    "print('N features:', len(feature_cols))\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27b3b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ¿Cuántas filas quedan con NaNs por lags/rolling? (esperable al inicio de cada tienda)\n",
    "na_rate = df_feat[feature_cols].isna().mean().sort_values(ascending=False)\n",
    "na_rate.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55964b8",
   "metadata": {},
   "source": [
    "## 6) Metadata reproducible (outputs/metadata.json)\n",
    "El archivo contiene:\n",
    "- Fechas exactas de train/val/test\n",
    "- Lista de features\n",
    "- Semilla\n",
    "- Versiones de librerías (si están instaladas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf68ddb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Captura de versiones (sin internet; solo lo instalado localmente)\n",
    "try:\n",
    "    from importlib.metadata import version, PackageNotFoundError\n",
    "except Exception:  # pragma: no cover\n",
    "    version = None\n",
    "\n",
    "def safe_version(pkg: str) -> str | None:\n",
    "    if version is None:\n",
    "        return None\n",
    "    try:\n",
    "        return version(pkg)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "libs = {\n",
    "    'python': sys.version.split()[0],\n",
    "    'numpy': safe_version('numpy'),\n",
    "    'pandas': safe_version('pandas'),\n",
    "    'matplotlib': safe_version('matplotlib'),\n",
    "    'seaborn': safe_version('seaborn'),\n",
    "    'statsmodels': safe_version('statsmodels'),\n",
    "    'scikit-learn': safe_version('scikit-learn'),\n",
    "}\n",
    "\n",
    "notes = {\n",
    "    'oracle_exog_assumption': 'All exogenous covariates are assumed available over the forecast horizon (oracle scenario).',\n",
    "    'val_weeks': str(VAL_WEEKS),\n",
    "    'test_weeks': str(TEST_WEEKS),\n",
    "}\n",
    "\n",
    "metadata_path = OUTPUTS_DIR / 'metadata.json'\n",
    "write_metadata(\n",
    "    metadata_path,\n",
    "    split_cfg=split_cfg,\n",
    "    feature_cols=feature_cols,\n",
    "    seed=SEED,\n",
    "    libs=libs,\n",
    "    notes=notes,\n",
    ")\n",
    "print('Wrote:', metadata_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15fdaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vista rápida del metadata\n",
    "print(metadata_path.read_text(encoding='utf-8')[:1200])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fe06fc",
   "metadata": {},
   "source": [
    "## 7) Checklist para los notebooks de modelos\n",
    "- Reutilizar `outputs/metadata.json` para recuperar split y lista de features\n",
    "- Mantener el supuesto oracle exog (explicitar)\n",
    "- Evitar leakage: lags/rolling solo con pasado; escalado fit solo en train\n",
    "- Guardar outputs estándar: predictions/metrics/figures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
