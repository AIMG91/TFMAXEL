{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fd41d1",
   "metadata": {},
   "source": [
    "# 02 — Ejecutar E0 (ablación FS0/FS1/FS2)\n",
    "\n",
    "Este notebook ejecuta el experimento **E0** para comparar el impacto de diferentes conjuntos de features (FS0/FS1/FS2) sobre modelos deep globales (LSTM / Transformer).\n",
    "\n",
    "## Split\n",
    "Usamos un split temporal global:\n",
    "- `val_weeks = 8`\n",
    "- `test_weeks = 39` (coherente con la evaluación final del proyecto)\n",
    "\n",
    "Estrategia de evaluación:\n",
    "1) Entrenar con **train** y evaluar en **val**.\n",
    "2) Reentrenar con **train+val** y evaluar en **test**.\n",
    "\n",
    "## Anti-leakage\n",
    "- Features causales (lags/rollings) vienen de `src.common.make_features`.\n",
    "- En modelos deep, el escalado se ajusta con el dataframe de entrenamiento del paso correspondiente.\n",
    "\n",
    "**Requisito**: ejecuta antes el notebook 01 para generar `outputs/E0_ablation/feature_sets.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e840f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "# Ensure PROJECT_ROOT is on sys.path so `import src.*` works reliably\n",
    "\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "\n",
    "PROJECT_ROOT = NOTEBOOK_DIR\n",
    "\n",
    "if (PROJECT_ROOT / 'src').exists() is False and (PROJECT_ROOT.parent / 'src').exists():\n",
    "\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "\n",
    "\n",
    "from src.e0_ablation_utils import (\n",
    "\n",
    "    collect_versions,\n",
    "\n",
    "    get_project_paths,\n",
    "\n",
    "    get_torch_device,\n",
    "\n",
    "    set_global_seed,\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "paths = get_project_paths(project_root=PROJECT_ROOT, output_dir='outputs/E0_ablation')\n",
    "\n",
    "DATA_PATH = paths.data_path\n",
    "\n",
    "OUTPUT_DIR = paths.output_dir\n",
    "\n",
    "\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "DEBUG = True  # [COMPLETAR: pon False para el run completo]\n",
    "\n",
    "\n",
    "\n",
    "seed_info = set_global_seed(SEED, deterministic=False)\n",
    "\n",
    "device, device_details = get_torch_device(prefer_cuda=True)\n",
    "\n",
    "\n",
    "\n",
    "print('PROJECT_ROOT:', PROJECT_ROOT)\n",
    "\n",
    "print('DATA_PATH:', DATA_PATH)\n",
    "\n",
    "print('OUTPUT_DIR:', OUTPUT_DIR)\n",
    "\n",
    "print('device:', device, device_details)\n",
    "\n",
    "print('seed:', seed_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7735d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load feature set specification from notebook 01\n",
    "feature_sets_path = OUTPUT_DIR / 'feature_sets.json'\n",
    "if not feature_sets_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f'Missing {feature_sets_path}. Run 01_data_and_feature_sets.ipynb first.'\n",
    "    )\n",
    "\n",
    "feature_sets = json.loads(feature_sets_path.read_text(encoding='utf-8'))\n",
    "print('Loaded feature sets:', list(feature_sets.keys()))\n",
    "\n",
    "# quick peek\n",
    "for k in ['FS0','FS1','FS2']:\n",
    "    print(k, 'n_features=', len(feature_sets[k]['feature_cols']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd12fd",
   "metadata": {},
   "source": [
    "## Configuración del experimento\n",
    "Ajusta hiperparámetros aquí. En modo `DEBUG=True`, se reducen epochs y/o se filtran tiendas para acelerar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc43b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.common import DEFAULT_LAGS, DEFAULT_ROLLINGS, EXOG_COLUMNS, load_data, make_features, temporal_split\n",
    "\n",
    "VAL_WEEKS = 8\n",
    "TEST_WEEKS = 39\n",
    "\n",
    "MODEL_SPECS = [\n",
    "    # (name, constructor)\n",
    "    ('lstm_exog', 'LSTMForecaster'),\n",
    "    ('transformer_exog', 'TransformerForecaster'),\n",
    "]\n",
    "\n",
    "# Deep model training params\n",
    "TRAINING_CFG = {\n",
    "    'lookback': 52,\n",
    "    'epochs': 3 if DEBUG else 20,\n",
    "    'batch_size': 64,\n",
    "    'lr': 1e-3,\n",
    "    'suppress_lookback_warning': False,\n",
    "}\n",
    "\n",
    "BASE_CFG = {\n",
    "    'lags': list(DEFAULT_LAGS),\n",
    "    'rollings': list(DEFAULT_ROLLINGS),\n",
    "}\n",
    "\n",
    "df = load_data(DATA_PATH)\n",
    "if DEBUG:\n",
    "    # speed-up: keep only a few stores\n",
    "    keep_stores = sorted(df['Store'].unique())[:5]\n",
    "    df = df[df['Store'].isin(keep_stores)].copy()\n",
    "    print('DEBUG stores:', keep_stores)\n",
    "\n",
    "print('df shape:', df.shape)\n",
    "print('date range:', df['Date'].min(), '→', df['Date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351c9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split temporal global (train/val/test)\n",
    "train_raw, val_raw, test_raw, split_cfg = temporal_split(df, val_weeks=VAL_WEEKS, test_weeks=TEST_WEEKS)\n",
    "print(split_cfg.as_dict())\n",
    "\n",
    "# sanity: no overlap\n",
    "assert train_raw['Date'].max() < val_raw['Date'].min()\n",
    "assert val_raw['Date'].max() < test_raw['Date'].min()\n",
    "print('train/val/test shapes:', train_raw.shape, val_raw.shape, test_raw.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3478dd",
   "metadata": {},
   "source": [
    "## Runner\n",
    "Ejecuta una combinación (modelo, feature set), guarda predicciones y métricas en `outputs/E0_ablation/<model>__<FS>/...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3f53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.experiments import _compute_metrics_frames\n",
    "\n",
    "from src.models.lstm_forecaster import LSTMForecaster\n",
    "from src.models.transformer_forecaster import TransformerForecaster\n",
    "\n",
    "MODEL_CTORS = {\n",
    "    'LSTMForecaster': LSTMForecaster,\n",
    "    'TransformerForecaster': TransformerForecaster,\n",
    "}\n",
    "\n",
    "\n",
    "def run_one(model_label: str, model_ctor_name: str, fs_name: str) -> dict:\n",
    "    fs = feature_sets[fs_name]\n",
    "\n",
    "    # Build features for this FS (we still use make_features and then filter columns)\n",
    "    df_feat, all_cols = make_features(df, add_calendar=bool(fs['add_calendar']))\n",
    "    used_cols = list(fs['feature_cols'])\n",
    "\n",
    "    # Sanity: required columns exist\n",
    "    missing = [c for c in used_cols if c not in df_feat.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f'Missing engineered columns for {fs_name}: {missing[:10]}')\n",
    "\n",
    "    # Split again but on engineered df (same dates)\n",
    "    train_df = df_feat[df_feat['Date'].isin(train_raw['Date'].unique())].copy()\n",
    "    val_df = df_feat[df_feat['Date'].isin(val_raw['Date'].unique())].copy()\n",
    "    test_df = df_feat[df_feat['Date'].isin(test_raw['Date'].unique())].copy()\n",
    "\n",
    "    # Config passed to model\n",
    "    cfg = {\n",
    "        **BASE_CFG,\n",
    "        **TRAINING_CFG,\n",
    "        'add_calendar': bool(fs['add_calendar']),\n",
    "        'exog_cols': list(fs['exog_cols']),\n",
    "        'feature_cols': used_cols,\n",
    "    }\n",
    "\n",
    "    run_dir = OUTPUT_DIR / f'{model_label}__{fs_name}'\n",
    "    (run_dir / 'predictions').mkdir(parents=True, exist_ok=True)\n",
    "    (run_dir / 'metrics').mkdir(parents=True, exist_ok=True)\n",
    "    (run_dir / 'figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # 1) Train -> predict val\n",
    "    t0 = time.time()\n",
    "    model = MODEL_CTORS[model_ctor_name]()\n",
    "    model.fit(train_df, cfg)\n",
    "    pred_val = model.predict(train_df, val_df, cfg)\n",
    "    val_sec = time.time() - t0\n",
    "\n",
    "    pred_val = pred_val.merge(\n",
    "        val_df[['Store','Date','Weekly_Sales']].rename(columns={'Weekly_Sales':'y_true'}),\n",
    "        on=['Store','Date'],\n",
    "        how='left',\n",
    "    )\n",
    "    pred_val = pred_val.rename(columns={'y_pred':'y_pred'})\n",
    "    pred_val['model'] = model_label\n",
    "    pred_val['feature_set'] = fs_name\n",
    "\n",
    "    mglob_val, mstore_val = _compute_metrics_frames(pred_val[['Store','Date','y_true','y_pred']], f'{model_label}__{fs_name}', group='VAL')\n",
    "    mglob_val['feature_set'] = fs_name\n",
    "    mglob_val['model'] = model_label\n",
    "\n",
    "    pred_val.to_csv(run_dir / 'predictions' / 'val_predictions.csv', index=False)\n",
    "    mglob_val.to_csv(run_dir / 'metrics' / 'val_metrics_global.csv', index=False)\n",
    "    mstore_val.to_csv(run_dir / 'metrics' / 'val_metrics_by_store.csv', index=False)\n",
    "\n",
    "    # 2) Train+Val -> predict test\n",
    "    t1 = time.time()\n",
    "    model2 = MODEL_CTORS[model_ctor_name]()\n",
    "    trainval_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    model2.fit(trainval_df, cfg)\n",
    "    pred_test = model2.predict(trainval_df, test_df, cfg)\n",
    "    test_sec = time.time() - t1\n",
    "\n",
    "    pred_test = pred_test.merge(\n",
    "        test_df[['Store','Date','Weekly_Sales']].rename(columns={'Weekly_Sales':'y_true'}),\n",
    "        on=['Store','Date'],\n",
    "        how='left',\n",
    "    )\n",
    "    pred_test['model'] = model_label\n",
    "    pred_test['feature_set'] = fs_name\n",
    "\n",
    "    mglob_test, mstore_test = _compute_metrics_frames(pred_test[['Store','Date','y_true','y_pred']], f'{model_label}__{fs_name}', group='TEST')\n",
    "    mglob_test['feature_set'] = fs_name\n",
    "    mglob_test['model'] = model_label\n",
    "\n",
    "    pred_test.to_csv(run_dir / 'predictions' / 'test_predictions.csv', index=False)\n",
    "    mglob_test.to_csv(run_dir / 'metrics' / 'test_metrics_global.csv', index=False)\n",
    "    mstore_test.to_csv(run_dir / 'metrics' / 'test_metrics_by_store.csv', index=False)\n",
    "\n",
    "    # Save run metadata\n",
    "    meta = {\n",
    "        'seed': SEED,\n",
    "        'debug': DEBUG,\n",
    "        'model': model_label,\n",
    "        'feature_set': fs_name,\n",
    "        'split': split_cfg.as_dict(),\n",
    "        'config': cfg,\n",
    "        'device': device,\n",
    "        'device_details': device_details,\n",
    "        'versions': collect_versions(),\n",
    "        'timing_sec': {\n",
    "            'val_fit_predict': float(val_sec),\n",
    "            'test_fit_predict': float(test_sec),\n",
    "        },\n",
    "    }\n",
    "    (run_dir / 'run_metadata.json').write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding='utf-8')\n",
    "\n",
    "    return {\n",
    "        'model': model_label,\n",
    "        'feature_set': fs_name,\n",
    "        'val_fit_predict_sec': float(val_sec),\n",
    "        'test_fit_predict_sec': float(test_sec),\n",
    "        **{k: float(mglob_test.iloc[0][k]) for k in ['MAE','RMSE','sMAPE']},\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e463991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run grid\n",
    "results = []\n",
    "\n",
    "for model_label, ctor_name in MODEL_SPECS:\n",
    "    for fs_name in ['FS0','FS1','FS2']:\n",
    "        print('===', model_label, fs_name, '===')\n",
    "        row = run_one(model_label=model_label, model_ctor_name=ctor_name, fs_name=fs_name)\n",
    "        results.append(row)\n",
    "\n",
    "summary = pd.DataFrame(results).sort_values(['model','feature_set']).reset_index(drop=True)\n",
    "display(summary)\n",
    "\n",
    "summary_path = OUTPUT_DIR / 'summary_metrics.csv'\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print('Saved:', summary_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf660c30",
   "metadata": {},
   "source": [
    "Siguiente: ejecutar **03_results_summary_and_plots.ipynb** para consolidación, deltas y visualizaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
