{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b2fd41d1",
   "metadata": {},
   "source": [
    "# 02 — Ejecutar E0 (ablación FS0/FS1/FS2)\n",
    "\n",
    "Este notebook ejecuta el experimento **E0** para comparar el impacto de diferentes conjuntos de features (FS0/FS1/FS2) sobre modelos deep globales (LSTM / Transformer).\n",
    "\n",
    "## Split\n",
    "Usamos un split temporal global:\n",
    "- `val_weeks = 8`\n",
    "- `test_weeks = 39` (coherente con la evaluación final del proyecto)\n",
    "\n",
    "Estrategia de evaluación:\n",
    "1) Entrenar con **train** y evaluar en **val**.\n",
    "2) Reentrenar con **train+val** y evaluar en **test**.\n",
    "\n",
    "## Anti-leakage\n",
    "- Features causales (lags/rollings) vienen de `src.common.make_features`.\n",
    "- En modelos deep, el escalado se ajusta con el dataframe de entrenamiento del paso correspondiente.\n",
    "\n",
    "**Requisito**: ejecuta antes el notebook 01 para generar `outputs/E0_ablation/feature_sets.json`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "7e840f73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: c:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\n",
      "DATA_PATH: C:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\data\\Walmart_Sales.csv\n",
      "OUTPUT_DIR: C:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\outputs\\E0_ablation\n",
      "DEVICE_SELECTED: cpu\n",
      "torch.cuda.is_available: False\n",
      "seed: {'seed': 42, 'deterministic': False, 'numpy': 'ok', 'torch': 'ok'}\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# Ensure PROJECT_ROOT is on sys.path so `import src.*` works reliably\n",
    "NOTEBOOK_DIR = Path.cwd()\n",
    "PROJECT_ROOT = NOTEBOOK_DIR\n",
    "if (PROJECT_ROOT / \"src\").exists() is False and (PROJECT_ROOT.parent / \"src\").exists():\n",
    "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
    "sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.e0_ablation_utils import (\n",
    "    collect_versions,\n",
    "    get_project_paths,\n",
    "    get_torch_device,\n",
    "    set_global_seed,\n",
    ")\n",
    "\n",
    "paths = get_project_paths(project_root=PROJECT_ROOT, output_dir=\"outputs/E0_ablation\")\n",
    "DATA_PATH = paths.data_path\n",
    "OUTPUT_DIR = paths.output_dir\n",
    "\n",
    "SEED = 42\n",
    "DEBUG = False  # set True solo para smoke-test rápido\n",
    "\n",
    "seed_info = set_global_seed(SEED, deterministic=False)\n",
    "# Forzar CPU explícitamente\n",
    "raw_device, device_details = get_torch_device(prefer_cuda=False)\n",
    "device = \"cpu\"\n",
    "if isinstance(device_details, dict):\n",
    "    device_details[\"requested\"] = \"cpu\"\n",
    "    device_details[\"torch_cuda_available\"] = bool(torch.cuda.is_available())\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "print(\"DATA_PATH:\", DATA_PATH)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "print(\"DEVICE_SELECTED:\", device)\n",
    "print(\"torch.cuda.is_available:\", torch.cuda.is_available())\n",
    "print(\"seed:\", seed_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9695cac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned: C:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\outputs\\E0_ablation\n"
     ]
    }
   ],
   "source": [
    "# Limpiar únicamente los outputs de E0\n",
    "import shutil\n",
    "OUT = OUTPUT_DIR\n",
    "if OUT.exists():\n",
    "    shutil.rmtree(OUT)\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Cleaned:\", OUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a6f7735d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created feature_sets.json at C:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\outputs\\E0_ablation\\feature_sets.json\n",
      "FS0 n_features= 11\n",
      "FS1 n_features= 14\n",
      "FS2 n_features= 19\n"
     ]
    }
   ],
   "source": [
    "# Cargar o reconstruir feature sets (FS0/FS1/FS2)\n",
    "feature_sets_path = OUTPUT_DIR / \"feature_sets.json\"\n",
    "if not feature_sets_path.exists():\n",
    "    # Construcción por defecto alineada con LAGS/ROLLINGS y EXOG_COLUMNS\n",
    "    lag_cols = [f\"lag_{k}\" for k in LAGS]\n",
    "    roll_cols = [c for w in ROLLINGS for c in (f\"roll_mean_{w}\", f\"roll_std_{w}\")]\n",
    "    calendar_cols = [\"weekofyear\", \"month\", \"year\"]\n",
    "\n",
    "    feature_sets = {\n",
    "        \"FS0\": {\n",
    "            \"add_calendar\": False,\n",
    "            \"exog_cols\": [],\n",
    "            \"feature_cols\": lag_cols + roll_cols,\n",
    "        },\n",
    "        \"FS1\": {\n",
    "            \"add_calendar\": True,\n",
    "            \"exog_cols\": [],\n",
    "            \"feature_cols\": lag_cols + roll_cols + calendar_cols,\n",
    "        },\n",
    "        \"FS2\": {\n",
    "            \"add_calendar\": True,\n",
    "            \"exog_cols\": list(EXOG_COLUMNS),\n",
    "            \"feature_cols\": lag_cols + roll_cols + list(EXOG_COLUMNS) + calendar_cols,\n",
    "        },\n",
    "    }\n",
    "    feature_sets_path.write_text(json.dumps(feature_sets, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "    print(\"Created feature_sets.json at\", feature_sets_path)\n",
    "else:\n",
    "    feature_sets = json.loads(feature_sets_path.read_text(encoding=\"utf-8\"))\n",
    "    print(\"Loaded feature sets:\", list(feature_sets.keys()))\n",
    "\n",
    "# quick peek\n",
    "for k in [\"FS0\", \"FS1\", \"FS2\"]:\n",
    "    print(k, \"n_features=\", len(feature_sets[k][\"feature_cols\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd12fd",
   "metadata": {},
   "source": [
    "## Configuración del experimento\n",
    "Ajusta hiperparámetros aquí. En modo `DEBUG=True`, se reducen epochs y/o se filtran tiendas para acelerar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc43b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_raw shape: (6435, 8)\n",
      "date range: 2010-02-05 00:00:00 → 2012-10-26 00:00:00\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import src.common as common_mod\n",
    "common_mod = importlib.reload(common_mod)\n",
    "from src.common import EXOG_COLUMNS, TEST_WEEKS as TEST_WEEKS_DEFAULT, get_E2_test_mask, load_data, make_features, temporal_split\n",
    "\n",
    "VAL_WEEKS = 8\n",
    "TEST_WEEKS = TEST_WEEKS_DEFAULT\n",
    "\n",
    "MODEL_SPECS = [\n",
    "    # (name, constructor)\n",
    "    (\"lstm_exog\", \"LSTMForecaster\"),\n",
    "    (\"transformer_exog\", \"TransformerForecaster\"),\n",
    "]\n",
    "\n",
    "# Carga de datos base\n",
    "df_raw = load_data(DATA_PATH)\n",
    "print(\"df_raw shape:\", df_raw.shape)\n",
    "print(\"date range:\", df_raw[\"Date\"].min(), \"→\", df_raw[\"Date\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31c4dd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAGS: [1, 2, 4, 8, 52]\n",
      "ROLLINGS: [4, 8, 12]\n"
     ]
    }
   ],
   "source": [
    "# Feature config (oficial, alineado con 10_Run_All_Experiments)\n",
    "LAGS = [1, 2, 4, 8, 52]\n",
    "ROLLINGS = [4, 8, 12]\n",
    "\n",
    "BASE_CFG = {\n",
    "    \"lags\": list(LAGS),\n",
    "    \"rollings\": list(ROLLINGS),\n",
    "}\n",
    "\n",
    "print(\"LAGS:\", LAGS)\n",
    "print(\"ROLLINGS:\", ROLLINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "309805ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST_MODE=False → usando todas las tiendas\n",
      "TRAINING_CFG: {'lookback': 52, 'epochs': 20, 'batch_size': 64, 'lr': 0.001, 'suppress_lookback_warning': False, 'early_stopping': True, 'patience': 3, 'device': 'cpu'}\n",
      "RUN_VALIDATION: strategic K_FOLDS: 1\n"
     ]
    }
   ],
   "source": [
    "# Fast/Full mode (CPU-friendly)\n",
    "FAST_MODE = False  # Cambia a True para smoke-test\n",
    "\n",
    "if FAST_MODE:\n",
    "    TRAINING_CFG = dict(\n",
    "        lookback=52,\n",
    "        epochs=3,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        suppress_lookback_warning=False,\n",
    "        early_stopping=True,\n",
    "        patience=1,\n",
    "        device=device,\n",
    "    )\n",
    "    MAX_STORES = 5\n",
    "    RUN_VALIDATION = \"strategic\"\n",
    "    K_FOLDS = 1\n",
    "else:\n",
    "    TRAINING_CFG = dict(\n",
    "        lookback=52,\n",
    "        epochs=20,\n",
    "        batch_size=64,\n",
    "        lr=1e-3,\n",
    "        suppress_lookback_warning=False,\n",
    "        early_stopping=True,\n",
    "        patience=3,\n",
    "        device=device,\n",
    "    )\n",
    "    MAX_STORES = None  # usar todas las tiendas\n",
    "    RUN_VALIDATION = \"strategic\"  # preferir strategic en CPU para evitar K folds\n",
    "    K_FOLDS = 1\n",
    "\n",
    "# Aplicar subconjunto opcional de tiendas para smoke-test CPU\n",
    "df = df_raw.copy()\n",
    "if MAX_STORES is not None:\n",
    "    keep_stores = sorted(df[\"Store\"].unique())[:MAX_STORES]\n",
    "    df = df[df[\"Store\"].isin(keep_stores)].copy()\n",
    "    print(f\"FAST_MODE={FAST_MODE} → usando {len(keep_stores)} tiendas: {keep_stores}\")\n",
    "else:\n",
    "    print(\"FAST_MODE=False → usando todas las tiendas\")\n",
    "\n",
    "print(\"TRAINING_CFG:\", TRAINING_CFG)\n",
    "print(\"RUN_VALIDATION:\", RUN_VALIDATION, \"K_FOLDS:\", K_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "351c9d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_start': '2010-02-05', 'train_end': '2011-12-02', 'val_start': '2011-12-09', 'val_end': '2012-01-27', 'test_start': '2012-02-03', 'test_end': '2012-10-26'}\n",
      "train/val/test shapes: (4320, 8) (360, 8) (1755, 8)\n"
     ]
    }
   ],
   "source": [
    "# Split temporal global (train/val/test)\n",
    "train_raw, val_raw, test_raw, split_cfg = temporal_split(df, val_weeks=VAL_WEEKS, test_weeks=TEST_WEEKS)\n",
    "print(split_cfg.as_dict())\n",
    "\n",
    "# sanity: no overlap\n",
    "assert train_raw['Date'].max() < val_raw['Date'].min()\n",
    "assert val_raw['Date'].max() < test_raw['Date'].min()\n",
    "print('train/val/test shapes:', train_raw.shape, val_raw.shape, test_raw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0a719fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAGS: [1, 2, 4, 8, 52]\n",
      "ROLLINGS: [4, 8, 12]\n",
      "n_lag_cols: 5 n_roll_cols: 6\n",
      "sample lag/roll cols: ['lag_1', 'lag_2', 'lag_4', 'lag_8', 'lag_52', 'roll_mean_4', 'roll_std_4', 'roll_mean_8', 'roll_std_8', 'roll_mean_12']\n",
      "E2 test window: 2012-02-03 → 2012-10-26\n",
      "Stores in mask: 45\n",
      "Points in eval_mask_common: 1755\n"
     ]
    }
   ],
   "source": [
    "# Build features once con la config oficial (LAGS/ROLLINGS) para compartir máscara\n",
    "lag_cols_expected = [f\"lag_{k}\" for k in LAGS]\n",
    "roll_cols_expected = [f\"roll_mean_{w}\" for w in ROLLINGS] + [f\"roll_std_{w}\" for w in ROLLINGS]\n",
    "\n",
    "# Nota: make_features devuelve (df_feat_full, feature_cols)\n",
    "df_feat_full, feature_cols_full = make_features(\n",
    "    df,\n",
    "    lags=LAGS,\n",
    "    rollings=ROLLINGS,\n",
    "    add_calendar=True,\n",
    ")\n",
    "\n",
    "lag_cols = [c for c in df_feat_full.columns if c.startswith(\"lag_\")]\n",
    "roll_cols = [c for c in df_feat_full.columns if c.startswith(\"roll_\")]\n",
    "print(\"LAGS:\", LAGS)\n",
    "print(\"ROLLINGS:\", ROLLINGS)\n",
    "print(\"n_lag_cols:\", len(lag_cols), \"n_roll_cols:\", len(roll_cols))\n",
    "print(\"sample lag/roll cols:\", (lag_cols + roll_cols)[:10])\n",
    "\n",
    "# Common evaluation mask: E2 test window ∩ rows without NaNs para FS2\n",
    "fs2_cols = feature_sets[\"FS2\"][\"feature_cols\"]\n",
    "e2_mask, e2_split = get_E2_test_mask(df_feat_full, test_weeks=TEST_WEEKS)\n",
    "mask_no_nan_fs2 = df_feat_full[fs2_cols + [\"Weekly_Sales\"]].notna().all(axis=1)\n",
    "eval_mask_common = e2_mask & mask_no_nan_fs2\n",
    "\n",
    "print(\"E2 test window:\", e2_split[\"test_start\"], \"→\", e2_split[\"test_end\"])\n",
    "print(\"Stores in mask:\", df_feat_full.loc[e2_mask, \"Store\"].nunique())\n",
    "print(\"Points in eval_mask_common:\", int(eval_mask_common.sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3478dd",
   "metadata": {},
   "source": [
    "## Runner\n",
    "Ejecuta una combinación (modelo, feature set), guarda predicciones y métricas en `outputs/E0_ablation/<model>__<FS>/...`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8d3f53c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.common as common\n",
    "common = importlib.reload(common)\n",
    "import src.models.lstm_forecaster as lstm_mod\n",
    "import src.models.transformer_forecaster as transf_mod\n",
    "lstm_mod = importlib.reload(lstm_mod)\n",
    "transf_mod = importlib.reload(transf_mod)\n",
    "from src.common import evaluate_predictions\n",
    "from src.models.lstm_forecaster import LSTMForecaster\n",
    "from src.models.transformer_forecaster import TransformerForecaster\n",
    "\n",
    "MODEL_CTORS = {\n",
    "    \"LSTMForecaster\": LSTMForecaster,\n",
    "    \"TransformerForecaster\": TransformerForecaster,\n",
    "}\n",
    "\n",
    "\n",
    "def run_one(model_label: str, model_ctor_name: str, fs_name: str) -> dict:\n",
    "    t_run_start = time.time()\n",
    "    fs = feature_sets[fs_name]\n",
    "\n",
    "    # Reuse the precomputed feature frame; only keep columns needed by the FS\n",
    "    df_feat = df_feat_full.copy()\n",
    "    used_cols = list(fs[\"feature_cols\"])\n",
    "\n",
    "    # Sanity: required columns exist\n",
    "    missing = [c for c in used_cols if c not in df_feat.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing engineered columns for {fs_name}: {missing[:10]}\")\n",
    "\n",
    "    train_df = df_feat[df_feat[\"Date\"].isin(train_raw[\"Date\"].unique())].copy()\n",
    "    val_df = df_feat[df_feat[\"Date\"].isin(val_raw[\"Date\"].unique())].copy()\n",
    "    test_df = df_feat[eval_mask_common].copy()\n",
    "\n",
    "    # Config passed to model\n",
    "    cfg = {\n",
    "        **BASE_CFG,\n",
    "        **TRAINING_CFG,\n",
    "        \"add_calendar\": bool(fs[\"add_calendar\"]),\n",
    "        \"exog_cols\": list(fs[\"exog_cols\"]),\n",
    "        \"feature_cols\": used_cols,\n",
    "        \"device\": device,\n",
    "        \"run_validation\": RUN_VALIDATION,\n",
    "        \"k_folds\": K_FOLDS,\n",
    "        \"max_stores\": MAX_STORES,\n",
    "    }\n",
    "\n",
    "    run_dir = OUTPUT_DIR / f\"{model_label}__{fs_name}\"\n",
    "    (run_dir / \"predictions\").mkdir(parents=True, exist_ok=True)\n",
    "    (run_dir / \"metrics\").mkdir(parents=True, exist_ok=True)\n",
    "    (run_dir / \"figures\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    print(f\"[{model_label}] device={cfg['device']}\")\n",
    "    print(f\"[{model_label}] torch.cuda.is_available={torch.cuda.is_available()}\")\n",
    "\n",
    "    # 1) Train -> predict val\n",
    "    t0 = time.time()\n",
    "    model = MODEL_CTORS[model_ctor_name]()\n",
    "    model.fit(train_df, cfg)\n",
    "    pred_val = model.predict(train_df, val_df, cfg)\n",
    "    val_sec = time.time() - t0\n",
    "\n",
    "    pred_val = pred_val.merge(\n",
    "        val_df[[\"Store\", \"Date\", \"Weekly_Sales\"]].rename(columns={\"Weekly_Sales\": \"y_true\"}),\n",
    "        on=[\"Store\", \"Date\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    pred_val[\"model\"] = model_label\n",
    "    pred_val[\"feature_set\"] = fs_name\n",
    "\n",
    "    report_val = run_dir / \"metrics\" / f\"debug_report_{model_label}_{fs_name}_VAL_{int(time.time())}.json\"\n",
    "    mglob_val, mstore_val, _ = evaluate_predictions(\n",
    "        pred_val[[\"Store\", \"Date\", \"y_true\", \"y_pred\"]],\n",
    "        group_keys=[\"Store\"],\n",
    "        model_name=model_label,\n",
    "        feature_set=fs_name,\n",
    "        group_label=\"VAL\",\n",
    "        report_path=report_val,\n",
    "    )\n",
    "\n",
    "    pred_val.to_csv(run_dir / \"predictions\" / \"val_predictions.csv\", index=False)\n",
    "    mglob_val.to_csv(run_dir / \"metrics\" / \"val_metrics_global.csv\", index=False)\n",
    "    mstore_val.to_csv(run_dir / \"metrics\" / \"val_metrics_by_store.csv\", index=False)\n",
    "\n",
    "    # 2) Train+Val -> predict test (using the common eval mask)\n",
    "    t1 = time.time()\n",
    "    model2 = MODEL_CTORS[model_ctor_name]()\n",
    "    trainval_df = pd.concat([train_df, val_df], ignore_index=True)\n",
    "    model2.fit(trainval_df, cfg)\n",
    "    pred_test = model2.predict(trainval_df, test_df, cfg)\n",
    "    test_sec = time.time() - t1\n",
    "\n",
    "    pred_test = pred_test.merge(\n",
    "        test_df[[\"Store\", \"Date\", \"Weekly_Sales\"]].rename(columns={\"Weekly_Sales\": \"y_true\"}),\n",
    "        on=[\"Store\", \"Date\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    pred_test[\"model\"] = model_label\n",
    "    pred_test[\"feature_set\"] = fs_name\n",
    "\n",
    "    report_test = run_dir / \"metrics\" / f\"debug_report_{model_label}_{fs_name}_TEST_{int(time.time())}.json\"\n",
    "    mglob_test, mstore_test, _ = evaluate_predictions(\n",
    "        pred_test[[\"Store\", \"Date\", \"y_true\", \"y_pred\"]],\n",
    "        group_keys=[\"Store\"],\n",
    "        model_name=model_label,\n",
    "        feature_set=fs_name,\n",
    "        group_label=\"TEST\",\n",
    "        report_path=report_test,\n",
    "    )\n",
    "\n",
    "    pred_test.to_csv(run_dir / \"predictions\" / \"test_predictions.csv\", index=False)\n",
    "    mglob_test.to_csv(run_dir / \"metrics\" / \"test_metrics_global.csv\", index=False)\n",
    "    mstore_test.to_csv(run_dir / \"metrics\" / \"test_metrics_by_store.csv\", index=False)\n",
    "\n",
    "    # Save run metadata\n",
    "    mae_global_micro = float(mglob_test.iloc[0][\"MAE\"])\n",
    "    mae_store_macro = float(mstore_test[\"MAE\"].mean()) if not mstore_test.empty else float(\"nan\")\n",
    "\n",
    "    runtime_sec = float(time.time() - t_run_start)\n",
    "\n",
    "    meta = {\n",
    "        \"seed\": SEED,\n",
    "        \"debug\": DEBUG,\n",
    "        \"model\": model_label,\n",
    "        \"feature_set\": fs_name,\n",
    "        \"split\": split_cfg.as_dict(),\n",
    "        \"config\": cfg,\n",
    "        \"device\": device,\n",
    "        \"device_details\": device_details,\n",
    "        \"versions\": collect_versions(),\n",
    "        \"timing_sec\": {\n",
    "            \"val_fit_predict\": float(val_sec),\n",
    "            \"test_fit_predict\": float(test_sec),\n",
    "            \"runtime_sec\": runtime_sec,\n",
    "        },\n",
    "        \"eval_mask_common_n\": int(eval_mask_common.sum()),\n",
    "    }\n",
    "    (run_dir / \"run_metadata.json\").write_text(json.dumps(meta, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
    "\n",
    "    return {\n",
    "        \"model\": model_label,\n",
    "        \"feature_set\": fs_name,\n",
    "        \"val_fit_predict_sec\": float(val_sec),\n",
    "        \"test_fit_predict_sec\": float(test_sec),\n",
    "        \"runtime_sec\": runtime_sec,\n",
    "        \"mae_global_micro\": mae_global_micro,\n",
    "        \"mae_store_macro\": mae_store_macro,\n",
    "        \"MAE\": mae_global_micro,\n",
    "        \"RMSE\": float(mglob_test.iloc[0][\"RMSE\"]),\n",
    "        \"sMAPE\": float(mglob_test.iloc[0][\"sMAPE\"]),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1e463991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAST_MODE=False | RUN_VALIDATION=strategic | device=cpu\n",
      "=== lstm_exog FS0 ===\n",
      "[lstm_exog] device=cpu\n",
      "[lstm_exog] torch.cuda.is_available=False\n",
      "[LSTM] Reducing lookback from 52 to 43 due to limited per-store history (min len=44 after dropna).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LSTM] Reducing lookback from 52 to 51 due to limited per-store history (min len=52 after dropna).\n",
      "=== lstm_exog FS1 ===\n",
      "[lstm_exog] device=cpu\n",
      "[lstm_exog] torch.cuda.is_available=False\n",
      "[LSTM] Reducing lookback from 52 to 43 due to limited per-store history (min len=44 after dropna).\n",
      "[LSTM] Reducing lookback from 52 to 51 due to limited per-store history (min len=52 after dropna).\n",
      "=== lstm_exog FS2 ===\n",
      "[lstm_exog] device=cpu\n",
      "[lstm_exog] torch.cuda.is_available=False\n",
      "[LSTM] Reducing lookback from 52 to 43 due to limited per-store history (min len=44 after dropna).\n",
      "[LSTM] Reducing lookback from 52 to 51 due to limited per-store history (min len=52 after dropna).\n",
      "=== transformer_exog FS0 ===\n",
      "[transformer_exog] device=cpu\n",
      "[transformer_exog] torch.cuda.is_available=False\n",
      "[Transformer] Reducing lookback from 52 to 43 due to limited per-store history (min len=44 after dropna).\n",
      "[Transformer] Reducing lookback from 52 to 51 due to limited per-store history (min len=52 after dropna).\n",
      "=== transformer_exog FS1 ===\n",
      "[transformer_exog] device=cpu\n",
      "[transformer_exog] torch.cuda.is_available=False\n",
      "[Transformer] Reducing lookback from 52 to 43 due to limited per-store history (min len=44 after dropna).\n",
      "[Transformer] Reducing lookback from 52 to 51 due to limited per-store history (min len=52 after dropna).\n",
      "=== transformer_exog FS2 ===\n",
      "[transformer_exog] device=cpu\n",
      "[transformer_exog] torch.cuda.is_available=False\n",
      "[Transformer] Reducing lookback from 52 to 43 due to limited per-store history (min len=44 after dropna).\n",
      "[Transformer] Reducing lookback from 52 to 51 due to limited per-store history (min len=52 after dropna).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>feature_set</th>\n",
       "      <th>mae_global_micro</th>\n",
       "      <th>mae_store_macro</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>sMAPE</th>\n",
       "      <th>val_fit_predict_sec</th>\n",
       "      <th>test_fit_predict_sec</th>\n",
       "      <th>runtime_sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lstm_exog</td>\n",
       "      <td>FS0</td>\n",
       "      <td>498803.916637</td>\n",
       "      <td>498803.916637</td>\n",
       "      <td>615527.684820</td>\n",
       "      <td>60.957842</td>\n",
       "      <td>4.477470</td>\n",
       "      <td>7.257845</td>\n",
       "      <td>11.888426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lstm_exog</td>\n",
       "      <td>FS1</td>\n",
       "      <td>715894.886941</td>\n",
       "      <td>715894.886941</td>\n",
       "      <td>819447.415702</td>\n",
       "      <td>109.518243</td>\n",
       "      <td>4.266515</td>\n",
       "      <td>7.655337</td>\n",
       "      <td>12.078657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lstm_exog</td>\n",
       "      <td>FS2</td>\n",
       "      <td>484668.400916</td>\n",
       "      <td>484668.400916</td>\n",
       "      <td>596656.506938</td>\n",
       "      <td>54.880722</td>\n",
       "      <td>3.776755</td>\n",
       "      <td>7.740952</td>\n",
       "      <td>11.646127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>transformer_exog</td>\n",
       "      <td>FS0</td>\n",
       "      <td>330957.363771</td>\n",
       "      <td>330957.363771</td>\n",
       "      <td>392481.497741</td>\n",
       "      <td>36.759372</td>\n",
       "      <td>6.555587</td>\n",
       "      <td>17.018241</td>\n",
       "      <td>23.731664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transformer_exog</td>\n",
       "      <td>FS1</td>\n",
       "      <td>490950.961268</td>\n",
       "      <td>490950.961268</td>\n",
       "      <td>577818.389430</td>\n",
       "      <td>57.917571</td>\n",
       "      <td>6.490634</td>\n",
       "      <td>14.738915</td>\n",
       "      <td>21.345433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>transformer_exog</td>\n",
       "      <td>FS2</td>\n",
       "      <td>433880.420127</td>\n",
       "      <td>433880.420127</td>\n",
       "      <td>501104.942122</td>\n",
       "      <td>51.617952</td>\n",
       "      <td>6.944340</td>\n",
       "      <td>16.509493</td>\n",
       "      <td>23.569092</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              model feature_set  mae_global_micro  mae_store_macro  \\\n",
       "0         lstm_exog         FS0     498803.916637    498803.916637   \n",
       "1         lstm_exog         FS1     715894.886941    715894.886941   \n",
       "2         lstm_exog         FS2     484668.400916    484668.400916   \n",
       "3  transformer_exog         FS0     330957.363771    330957.363771   \n",
       "4  transformer_exog         FS1     490950.961268    490950.961268   \n",
       "5  transformer_exog         FS2     433880.420127    433880.420127   \n",
       "\n",
       "            RMSE       sMAPE  val_fit_predict_sec  test_fit_predict_sec  \\\n",
       "0  615527.684820   60.957842             4.477470              7.257845   \n",
       "1  819447.415702  109.518243             4.266515              7.655337   \n",
       "2  596656.506938   54.880722             3.776755              7.740952   \n",
       "3  392481.497741   36.759372             6.555587             17.018241   \n",
       "4  577818.389430   57.917571             6.490634             14.738915   \n",
       "5  501104.942122   51.617952             6.944340             16.509493   \n",
       "\n",
       "   runtime_sec  \n",
       "0    11.888426  \n",
       "1    12.078657  \n",
       "2    11.646127  \n",
       "3    23.731664  \n",
       "4    21.345433  \n",
       "5    23.569092  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\usuario\\Documents\\Master AI\\TFM\\MEMORIA 2.0\\outputs\\E0_ablation\\summary_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Run grid\n",
    "results = []\n",
    "\n",
    "print(f\"FAST_MODE={FAST_MODE} | RUN_VALIDATION={RUN_VALIDATION} | device={device}\")\n",
    "for model_label, ctor_name in MODEL_SPECS:\n",
    "    for fs_name in [\"FS0\", \"FS1\", \"FS2\"]:\n",
    "        print(\"===\", model_label, fs_name, \"===\")\n",
    "        row = run_one(model_label=model_label, model_ctor_name=ctor_name, fs_name=fs_name)\n",
    "        results.append(row)\n",
    "\n",
    "summary = (\n",
    "    pd.DataFrame(results)\n",
    "    .sort_values([\"model\", \"feature_set\"])\n",
    "    .reset_index(drop=True)\n",
    ")[\n",
    "    [\n",
    "        \"model\",\n",
    "        \"feature_set\",\n",
    "        \"mae_global_micro\",\n",
    "        \"mae_store_macro\",\n",
    "        \"RMSE\",\n",
    "        \"sMAPE\",\n",
    "        \"val_fit_predict_sec\",\n",
    "        \"test_fit_predict_sec\",\n",
    "        \"runtime_sec\",\n",
    "    ]\n",
    "]\n",
    "display(summary)\n",
    "\n",
    "summary_path = OUTPUT_DIR / \"summary_metrics.csv\"\n",
    "summary.to_csv(summary_path, index=False)\n",
    "print(\"Saved:\", summary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f21fd296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sanity check passed. n_points: 1755\n",
      "n_stores: 45\n",
      "date_min/date_max: 2012-02-03 → 2012-10-26\n",
      "y_true_mean/y_pred_mean: 1043440.6767464387 / 613494.9440552092\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample_pred_path = OUTPUT_DIR / \"transformer_exog__FS2\" / \"predictions\" / \"test_predictions.csv\"\n",
    "if sample_pred_path.exists():\n",
    "    mask_df = df_feat_full.loc[eval_mask_common, [\"Store\", \"Date\"]]\n",
    "    sample_pred = pd.read_csv(sample_pred_path)\n",
    "    sample_pred[\"Date\"] = pd.to_datetime(sample_pred[\"Date\"])\n",
    "    sample_pred_common = sample_pred.merge(mask_df, on=[\"Store\", \"Date\"], how=\"inner\")\n",
    "\n",
    "    mglob_chk, mstore_chk, _ = evaluate_predictions(\n",
    "        sample_pred_common[[\"Store\", \"Date\", \"y_true\", \"y_pred\"]],\n",
    "        group_keys=[\"Store\"],\n",
    "        model_name=\"transformer_exog\",\n",
    "        feature_set=\"FS2\",\n",
    "        group_label=\"TEST_SANITY\",\n",
    "    )\n",
    "\n",
    "    mae_micro_chk = float(mglob_chk.iloc[0][\"MAE\"])\n",
    "    mae_macro_chk = float(mstore_chk[\"MAE\"].mean()) if not mstore_chk.empty else float(\"nan\")\n",
    "    row = summary[(summary[\"model\"] == \"transformer_exog\") & (summary[\"feature_set\"] == \"FS2\")].iloc[0]\n",
    "\n",
    "    assert np.isclose(mae_micro_chk, row[\"mae_global_micro\"], atol=1e-6)\n",
    "    assert np.isclose(mae_macro_chk, row[\"mae_store_macro\"], atol=1e-6)\n",
    "\n",
    "    print(\"Sanity check passed. n_points:\", len(sample_pred_common))\n",
    "    print(\"n_stores:\", sample_pred_common[\"Store\"].nunique())\n",
    "    print(\n",
    "        \"date_min/date_max:\",\n",
    "        sample_pred_common[\"Date\"].min().date(),\n",
    "        \"→\",\n",
    "        sample_pred_common[\"Date\"].max().date(),\n",
    "    )\n",
    "    print(\n",
    "        \"y_true_mean/y_pred_mean:\",\n",
    "        sample_pred_common[\"y_true\"].mean(),\n",
    "        \"/\",\n",
    "        sample_pred_common[\"y_pred\"].mean(),\n",
    "    )\n",
    "else:\n",
    "    print(\"Sanity check skipped (missing predictions for transformer_exog__FS2).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf660c30",
   "metadata": {},
   "source": [
    "Siguiente: ejecutar **09_results_summary_and_plots.ipynb** para consolidación, deltas y visualizaciones."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
